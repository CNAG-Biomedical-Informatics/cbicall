{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\ud83c\udfe0 Introduction","text":"Welcome to the documentation for CBICall <p>CBICall (CNAG Biomedical Informatics framework for variant Calling) is a lightweight, reproducible framework for germline variant calling developed at CNAG. Built for Illumina WES/WGS data, CBICall wraps established best-practices (BWA \u2192 GATK \u2192 VQSR / hard-filters) into easy-to-run Bash and Snakemake workflows so labs can produce high-quality single-sample and cohort VCFs with minimal fuss. \ud83e\uddec</p>"},{"location":"#why-cbicall","title":"Why CBICall?","text":"<ul> <li>Implements GATK best practices (GATK-4.6 and legacy GATK3.5) tuned for real project needs.  </li> <li>Supports both single-sample and cohort pipelines (WES / WGS) with GenomicsDBImport and optional per-chromosome sharding.  </li> <li>Handles mitochondrial DNA (mtDNA) analysis through MToolBox integration for heteroplasmy-aware calling and mtDNA-specific processing.  </li> <li>Simple YAML configuration and sensible defaults to get you running quickly.  </li> <li>Transparent, auditable logs and outputs for QC and downstream analysis.</li> </ul>"},{"location":"#key-features","title":"Key features","text":"<ul> <li>Per-sample preprocessing: alignment, read groups, merging, duplicate marking, BQSR.  </li> <li>Per-sample GVCF generation and scalable joint genotyping (GenomicsDBImport \u2192 GenotypeGVCFs).  </li> <li>Variant quality control: VQSR when cohort size permits, with reproducible hard-filter fallbacks.  </li> <li>mtDNA support: MToolBox-based workflows for mitochondrial assembly, heteroplasmy estimation and annotation.  </li> <li>Small-footprint workflows: Bash and Snakemake variants, plus optional containerized deployment.  </li> <li>Handy utility scripts: coverage stats, sex determination, basic cohort QC.</li> </ul>"},{"location":"about/about/","title":"About","text":"<p>CBICall has been developed at CNAG, Barcelona, Spain.</p>"},{"location":"about/about/#developers","title":"Developers","text":"CLIDocumentation <ul> <li>Manuel Rueda</li> </ul> <ul> <li>Manuel Rueda. </li> </ul> <p>Project documentation was created using Material for MkDocs.</p>"},{"location":"about/about/#acknowledgments","title":"Acknowledgments","text":"CNAG <ul> <li>Ivo G. Gut and his team</li> </ul>"},{"location":"about/citation/","title":"Citation for ClarID-Tools","text":"<p>Citation</p> <p>TBD</p> <p>Funding agencies</p> <ul> <li>TBD</li> </ul>"},{"location":"download-and-installation/docker-based/","title":"Containerized Installation","text":""},{"location":"download-and-installation/docker-based/#downloading-required-databases-and-software","title":"Downloading Required Databases and Software","text":"<p>Begin by downloading the required databases and software. Save the data outside the container; this preserves it across container restarts and lets you update the software without downloading the data again.</p> <p>Install dependencies for Python 3:</p> <pre><code>pip3 install -r requirements.txt\n</code></pre> <p>Finally, navigate to a directory where you want the databases stored and execute:</p> <pre><code>wget https://raw.githubusercontent.com/mrueda/cbicall/refs/heads/main/scripts/01_download_external_data.py\npython3 ./01_download_external_data.py\n</code></pre> <p>Note: Google Drive can be a tad restrictive with the download. If you get an error, please use the error URL link in a browser and you should be able to retrieve it there.</p> <p>Once downloaded, perform a checksum to make sure the files were not corrupted:</p> <pre><code>md5sum -c data.tar.gz.md5\n</code></pre> <p>Now let's reassemble the split files into the original tar archive:</p> <pre><code>cat data.tar.gz.part-?? &gt; data.tar.gz\n</code></pre> <p>Clean up split files to save space (when you think you are ready!):</p> <pre><code>rm data.tar.gz.part-??\n</code></pre> <p>Extract the tar archive:</p> <pre><code>tar -xzvf data.tar.gz\n</code></pre> <p>Finally, in the <code>cbicall</code> repo:</p> <p>Change <code>DATADIR</code> variable in <code>workflows/bash/*/parameters.sh</code> and <code>workflows/snakemake/*/config.yaml</code> so that it matches the location of your downloaded data.</p>"},{"location":"download-and-installation/docker-based/#method-2-installing-from-docker-hub-fast","title":"Method 2: Installing from Docker Hub (fast)","text":"<p>Pull the latest Docker image from Docker Hub:</p> <pre><code>docker pull manuelrueda/cbicall:latest\ndocker image tag manuelrueda/cbicall:latest cnag/cbicall:latest\n</code></pre>"},{"location":"download-and-installation/docker-based/#method-3-installing-from-dockerfile-slow","title":"Method 3: Installing from Dockerfile (slow)","text":"<p>Download the <code>Dockerfile</code> from GitHub:</p> <pre><code>wget https://raw.githubusercontent.com/CNAG-Biomedical-Informatics/cbicall/main/docker/Dockerfile\n</code></pre> <p>Then build the container:</p> <ul> <li>For Docker version 19.03 and above (supports buildx):</li> </ul> <pre><code>docker buildx build -t cnag/cbicall:latest .\n</code></pre> <ul> <li>For Docker versions older than 19.03 (no buildx support):</li> </ul> <pre><code>docker build -t cnag/cbicall:latest .\n</code></pre>"},{"location":"download-and-installation/docker-based/#running-and-interacting-with-the-container","title":"Running and Interacting with the Container","text":"<pre><code># Please update '/absolute/path/to/cbicall-data' with your actual local data path\ndocker run -tid --volume /absolute/path/to/cbicall-data:/cbicall-data -e USERNAME=root --name cbicall cnag/cbicall:latest\n</code></pre> <p>To connect to the container:</p> <pre><code>docker exec -ti cbicall bash\n</code></pre> <p>Finally, inside the <code>cbicall</code> repo:</p> <p>Change <code>DATADIR</code> variable in <code>workflows/bash/parameters.sh</code> and <code>workflows/snakemake/config.yaml</code> to <code>/cbicall-data</code>.</p>"},{"location":"download-and-installation/docker-based/#performing-unit-test","title":"Performing unit test","text":"<p>Inside the container</p> <pre><code>cd examples/input\n./run_test.sh\n</code></pre>"},{"location":"download-and-installation/docker-based/#system-requirements","title":"System requirements","text":"<ul> <li>OS/ARCH supported: linux/amd64 and linux/arm64.</li> <li>Ideally a Debian-based distribution (Ubuntu or Mint), but any other (e.g., CentOS, OpenSUSE) should do as well (untested).</li> <li>16GB of RAM</li> <li>&gt;= 1 core (ideally i7 or Xeon).</li> <li>At least 100GB HDD.</li> </ul>"},{"location":"download-and-installation/docker-based/#common-errors-symptoms-and-treatment","title":"Common errors: Symptoms and treatment","text":"<ul> <li>Dockerfile:<pre><code>  * DNS errors\n\n    - Error: Temporary failure resolving 'foo'\n\n      Solution: https://askubuntu.com/questions/91543/apt-get-update-fails-to-fetch-files-temporary-failure-resolving-error\n</code></pre> </li> </ul>"},{"location":"download-and-installation/non-containerized/","title":"Non-containerized installation","text":""},{"location":"download-and-installation/non-containerized/#method-1-download-from-github","title":"Method 1: Download from GitHub","text":"<p>First, we need to install a few system components (note you might have them already in your system):</p> <pre><code>sudo apt install gcc make git cpanminus libperl-dev\n</code></pre> <p>Use <code>git clone</code> to get the latest (stable) version:</p> <pre><code>git clone https://github.com/CNAG-Biomedical-Informatics/cbicall.git\ncd cbicall\n</code></pre> <p>If you only new to update to the lastest version do:</p> <pre><code>git pull\n</code></pre> <p>We use <code>cpanm</code> to install the CPAN modules. We'll install the dependencies at <code>~/perl5</code>:</p> <p><pre><code>cpanm --local-lib=~/perl5 local::lib &amp;&amp; eval $(perl -I ~/perl5/lib/perl5/ -Mlocal::lib)\ncpanm --notest --installdeps .\nbin/cbicall\n</code></pre> Testing the deployment:</p> <pre><code>prove\n</code></pre> <p>To ensure Perl recognizes your local modules every time you start a new terminal, run:</p> <pre><code>echo 'eval $(perl -I ~/perl5/lib/perl5/ -Mlocal::lib)' &gt;&gt; ~/.bashrc\n</code></pre>"},{"location":"download-and-installation/non-containerized/#install-required-external-software","title":"Install required external software","text":"<p>Install dependencies for Python 3:</p> <pre><code>pip3 install -r requirements.txt\n</code></pre> <p>Finally, navigate to a directory where you want the databases stored and execute:</p> <pre><code>python3 $path_to_cbicall/scripts/01_download_external_data.py  # Replace $path_to_cbicall with your CBICall installation path.\n</code></pre> <p>Note: Google Drive can be a tad restrictive with the download. If you get an error, please use the error URL link in a browser and you should be able to retrieve it there.</p> <p>Once downloaded, perform a checksum to make sure the files were not corrupted:</p> <pre><code>md5sum -c data.tar.gz.md5\n</code></pre> <p>Now let's reassemble the split files into the original tar archive:</p> <pre><code>cat data.tar.gz.part-?? &gt; data.tar.gz\n</code></pre> <p>Clean up split files to save space (when you think you are ready!):</p> <pre><code>rm data.tar.gz.part-??\n</code></pre> <p>Extract the tar archive:</p> <pre><code>tar -xzvf data.tar.gz\n</code></pre> <p>Finally, in the <code>cbicall</code> repo:</p> <p>Change <code>DATADIR</code> variable in <code>workflows/bash/*/parameters.sh</code> and <code>workflows/snakemake/*/config.yaml</code> so that it matches the location of your downloaded data.</p> <p>Ok, finally we are going to install <code>Java 8</code> in case you don't have it already:</p> <pre><code>sudo apt install openjdk-8-jdk # In some systems you maight need Java 17 -&gt; openjdk-17-jre\n</code></pre>"},{"location":"download-and-installation/non-containerized/#performing-unit-test","title":"Performing unit test","text":"<p>Once you are in the root directory of the repo:</p> <pre><code>cd examples/input\n./run_test.sh\n</code></pre>"},{"location":"download-and-installation/non-containerized/#system-requirements","title":"System requirements","text":"<ul> <li>OS/ARCH supported: linux/amd64 and linux/arm64.</li> <li>Ideally a Debian-based distribution (Ubuntu or Mint), but any other (e.g., CentOS, OpenSUSE) should do as well (untested).</li> <li>Perl 5 (&gt;= 5.36 core; installed by default in many Linux distributions). Check the version with <code>perl -v</code></li> <li>Java 8</li> <li>16GB of RAM</li> <li>&gt;= 1 core (ideally i7 or Xeon).</li> <li>At least 100GB HDD.</li> </ul>"},{"location":"download-and-installation/non-containerized/#platform-compatibility","title":"Platform Compatibility","text":"<p>This distribution is written in pure Perl and is intended to run on any platform supported by Perl 5. It has been tested on Debian Linux and macOS. Please report any issues.</p>"},{"location":"download-and-installation/non-containerized/#common-errors-symptoms-and-treatment","title":"Common errors: Symptoms and treatment","text":"<ul> <li> <p>Perl errors:</p> <ul> <li>Foo</li> </ul> <p>Solution: </p> <p><code>Bar</code></p> </li> </ul>"},{"location":"help/faq/","title":"Frequently Asked Questions","text":""},{"location":"help/faq/#wes-wgs","title":"WES / WGS","text":"Foo? <p>Bar.</p>"},{"location":"help/faq/#last-change-2025-10-15-by-manuel-rueda","title":"last change 2025-10-15 by Manuel Rueda","text":""},{"location":"help/faq/#mtdna","title":"mtDNA","text":""},{"location":"help/faq/#general","title":"General","text":"How do I cite CBICall? <p>You can cite the CBICalls paper. Thx!</p> <p>Citation</p> <p>TBD</p>"},{"location":"help/faq/#last-change-2025-10-15-by-manuel-rueda_1","title":"last change 2025-10-15 by Manuel Rueda","text":""},{"location":"usage/quickstart/","title":"Quickstart","text":"<p>This guide provides a one-page cheat sheet for common commands:</p> <pre><code># Display help for the tool\nbin/cbicall --help\n</code></pre> <pre><code># Display man for the tool\nbin/cbicall --man\n</code></pre> <pre><code># Run CBICall with different options\n$ bin/cbicall -p param_file.yaml -t 6\n$ bin/cbicall -p param_file.yaml -t 4 -verbose\n$ bin/cbicall -p param_file.yaml -t 16 &gt; log 2&gt;&amp;1\n$ $path_to_cbicall/bin/cbicall -p param_file.yaml -t 8 -debug 5\n</code></pre>"},{"location":"usage/usage/","title":"Usage","text":"<p>CNAG Biomedical Informatics framework for variant Calling</p> <p> </p> <p>\ud83d\udcd8 Documentation: cnag-biomedical-informatics.github.io/cbicall</p> <p>\ud83d\udc33 Docker Hub Image: hub.docker.com/r/manuelrueda/cbicall/tags</p>"},{"location":"usage/usage/#table-of-contents","title":"Table of contents","text":"<ul> <li>Description</li> <li>Name</li> <li>Synopsis</li> <li>Summary</li> <li>Installation</li> <li>Non-Containerized</li> <li>Containerized</li> <li>How to run cbicall</li> <li>Citation</li> <li>Author</li> <li>License</li> </ul>"},{"location":"usage/usage/#name","title":"NAME","text":"<p>CBICall: CNAG Biomedical Informatics Framework for Variant Calling on Illumina DNA-seq (germline) NGS Data.</p>"},{"location":"usage/usage/#synopsis","title":"SYNOPSIS","text":"<pre><code>cbicall -p &lt;parameters_file.yaml&gt; -t &lt;n_threads&gt; [options]\n\nArguments:\n  -p|param          Parameters input file (YAML)\n  -t|threads        Number of CPUs/Cores/Threads\n\nOptions:\n  -debug            Debugging level (from 1 to 5; 5 is maximum verbosity)\n  -h|help           Brief help message\n  -man              Full documentation\n  -v                Show version information\n  -verbose          Enable verbose output\n  -nc|no-color      Do not print colors to STDOUT\n  -ne|no-emoji      Do not print emojis to STDOUT\n</code></pre>"},{"location":"usage/usage/#summary","title":"SUMMARY","text":"<p>CBICall (CNAG Biomedical Informatics framework for variant Calling) is a computational framework designed for variant calling analysis using Illumina Next-Generation Sequencing (NGS) data.</p>"},{"location":"usage/usage/#how-to-run-cbicall","title":"HOW TO RUN CBICALL","text":"<p>CBICall execution requires:</p> <ul> <li> <p>Input Files</p> <p>A folder containing Paired-End FASTQ files (e.g., <code>MA00001_exome/MA0000101P_ex/*{R1,R2}*fastq.gz</code>).</p> <p>You have a <code>examples/input/</code> directory with input data that you can use for testing.</p> </li> <li> <p>Parameters File</p> <p>A YAML-formatted parameters file controlling pipeline execution.</p> </li> </ul> <p>Below are the parameters that can be customized, along with their default values. Parameters must be separated from their values by whitespace or tabs.</p>"},{"location":"usage/usage/#essential-parameters","title":"Essential Parameters","text":"<pre><code>mode:            single  \npipeline:        wes          \nsample:          undef        \nsample_map:      undef\nworkflow_engine:   bash\ngatk_version:      gatk3.5\ncleanup_bam:       false\n</code></pre>"},{"location":"usage/usage/#optional-parameters-currently-unused","title":"Optional Parameters (Currently Unused)","text":"<pre><code>organism:        Homo Sapiens        \ntechnology:      Illumina HiSeq\n</code></pre> <p>CBICall will create a dedicated project directory (<code>cbicall_*</code>) to store analysis outputs. This design allows multiple independent runs concurrently without modifying original input files.</p> <p>Below is a detailed description of key parameters:</p> <ul> <li> <p>cleanup_bam</p> <p>Set it to <code>true</code> to delete <code>01_bam/*.{bam,bai}</code>.</p> </li> <li> <p>gatk_version</p> <p>Supported values: <code>gatk3.5</code> or <code>gatk4.6</code>.</p> </li> <li> <p>mode</p> <p>Two modes are supported: <code>single</code> (default, for individual samples) and <code>cohort</code> (for family/cohort-based analyses).</p> </li> <li> <p>pipeline</p> <p>Specifies the analysis pipeline. Currently available options: <code>wes</code> (whole-exome sequencing) and <code>mit</code> (mitochondrial DNA analysis). Note: to run <code>cohort</code> analysis, first complete a <code>single</code> analysis for each sample.</p> </li> <li> <p>projectdir</p> <p>The prefix for dir name (e.g., 'cancer_sample_001'). Note that it can also contain a path (e.g., foo/cancer_sample_001).</p> <p>Note: Such directory will be always created below the sample directory. The script will automatically add an unique identifier to each job.</p> </li> <li> <p>sample</p> <p>Path (relative or absolute) to the directory containing FASTQ files for analysis. See the <code>examples</code> directory for detailed guidance.</p> <p>Example:</p> <p>examples/input/CNAG999_exome/CNAG99901P_ex</p> </li> <li> <p>sample_map (cohort-mode only)</p> <p>Path (relative or absolute) to the file containing the sample ids and teh paths for the GVCF files</p> <p>See example here</p> </li> <li> <p>workflow_engine</p> <p>Supported workflow engines: <code>bash</code> or <code>snakemake</code>.</p> </li> </ul>"},{"location":"usage/usage/#example-commands","title":"Example Commands","text":"<pre><code>$ bin/cbicall -p param_file.yaml -t 8\n$ bin/cbicall -p param_file.yaml -t 4 -verbose\n$ bin/cbicall -p param_file.yaml -t 16 &gt; log 2&gt;&amp;1\n$ $path_to_cbicall/bin/cbicall -p param_file.yaml -t 8 -debug 5\n</code></pre> <p>Note: For Trio analyses, unique (de novo) variant rates for probands typically should be ~1%, and ~10% for parents. Significant deviations may indicate issues.</p>"},{"location":"usage/usage/#addendum-nomenclature-guidelines","title":"ADDENDUM: Nomenclature Guidelines","text":"<p>All parts must follow a strict character count, and everything after the underscore is mandatory.</p>"},{"location":"usage/usage/#directory-naming","title":"Directory Naming","text":"<ul> <li> <p>Format: <code>[ProjectCode]_[SampleType]</code></p> <ul> <li> <ul> <li><code>ProjectCode</code>: Exactly 7 characters [a-zA-Z0-9] (e.g., <code>MA99999</code>)</li> </ul> </li> <li> <ul> <li><code>SampleType</code>: Must be <code>exome</code> (5 characters)</li> </ul> </li> </ul> <p>Example:</p> <pre><code>MA99999_exome\n</code></pre> <p>Total: 7 + 1 + 5 = 13 characters.</p> </li> </ul>"},{"location":"usage/usage/#subdirectory-naming","title":"Subdirectory Naming","text":"<ul> <li> <p>Format: <code>[ProjectCode][SampleID][Role]_[SampleTypeShort]</code></p> <ul> <li> <ul> <li><code>ProjectCode</code>: 7 characters ([a-zA-Z0-9] e.g., <code>MA99999</code>)</li> </ul> </li> <li> <ul> <li><code>SampleID</code>: 2 characters (e.g., <code>01</code>)</li> </ul> </li> <li> <ul> <li><code>Role</code>: 1 character (e.g., <code>P</code> for Proband, <code>F</code> for Father, <code>M</code> for Mother)</li> </ul> </li> <li> <ul> <li><code>SampleTypeShort</code>: Must be <code>ex</code> (2 characters)</li> </ul> </li> </ul> <p>Example:</p> <pre><code>MA9999901F_ex\n</code></pre> <p>Total: 7 + 2 + 1 + 1 + 2 = 13 characters (excluding any file extension).</p> </li> </ul>"},{"location":"usage/usage/#fastq-naming-convention","title":"FASTQ Naming Convention","text":"<p>This convention is adapted from the following document:</p> <p>Document</p> <p>We have added a custom suffix to indicate sequencing type:</p> <pre><code>- _ex for exome sequencing\n- _wg for whole genome sequencing\n</code></pre> <p>Example:</p> <pre><code>MA0004701P_ex_S5_L001_R1_001.fastq.gz\n</code></pre> <p>In summary, you need to have something like this:</p> <pre><code>MA00001_exome/MA0000101P_ex/MA0000101P_ex_S1_L001_R?_001.fastq.gz\n</code></pre>"},{"location":"usage/usage/#system-requirements","title":"SYSTEM REQUIREMENTS","text":"<p>CBICall is optimized for multi-core Linux desktop, workstation, or server environments. Snakemake-based workflows can also be adapted for HPC clusters.</p> <p>Recommended specifications:</p> <pre><code>* Works in amd64 and arm64 archs (M-based Macs).\n* Ideally a Debian-based distribution (Ubuntu or Mint), but any other (e.g., CentOS, OpenSUSE) should do as well (untested).\n* &gt;= 8 GB RAM.\n* &gt;= 4 CPU cores (Intel i7 or Xeon preferred).\n* &gt;= 250 GB HDD space.\n* Perl &gt;= 5.36 and required CPAN modules (install via C&lt;cpanm --notest --installdeps .&gt;).\n* Java 8 (install via C&lt;sudo apt install openjdk-8-jdk&gt;).\n* Snakemake (install via C&lt;pip3 install -r requirements.txt&gt;).\n</code></pre> <p>Perl scripts in CBICall use minimal RAM (~2% of a 16 GB system). Genome mapping with BWA benefits from higher memory but lacks built-in RAM limits. Its usage depends on thread count and reference size. To constrain BWA's memory, external tools like shell <code>ulimit</code> are required. In contrast, GATK and Picard default to 8 GB RAM, adjustable via the configuration file.</p> <p>Parallel execution is supported but does not scale linearly. Optimal performance is achieved using ~ 4 threads per task. For example, with 12 cores, running 3 tasks in parallel with 4 cores each is typically more efficient than one task with all 12 cores. See example in figure below:</p> <p></p> <p>Unit/integration tests are conducted manually by verifying CSV and VCF outputs against established test datasets.</p>"},{"location":"usage/usage/#supported-pipelines","title":"SUPPORTED PIPELINES","text":"<p>The following table shows valid pipeline and mode combinations for each GATK version:</p> GATK Version wes_single wes_cohort wgs_single wgs_cohort mit_single mit_cohort gatk3.5 + + - - + + gatk4.6 + + + + - - <p>Date: Oct-2025</p>"},{"location":"usage/usage/#capture-kits","title":"Capture Kits","text":"<p>* For GATK version 3.5: Exome capture is based on Agilent SureSelect.</p> <p>* For GATK version 4.6: Exome and WGS reference is based on the GATK bundle (b37).</p>"},{"location":"usage/usage/#common-errors-and-troubleshooting","title":"COMMON ERRORS AND TROUBLESHOOTING","text":"<ul> <li> <p>GATK|Picard Errors (wes_single.sh or wes_cohort.sh)</p> <ul> <li> <p>Error: <code>NaN LOD value assigned</code> in recalibration steps.</p> <p>Occurs due to insufficient INDEL variants (typically fewer than 8000) for negative model training. The default threshold is 8000.</p> <p>Solution: Increase minimum INDEL count (e.g., to &gt;8000) in relevant pipeline scripts. Only rerun failed samples.</p> </li> <li> <p>Error: <code>there aren't enough columns for line ... dbsnp_137.hg19.vcf</code></p> <p>Solution: Remove the problematic line from the VCF file and document changes in a README file.</p> </li> <li> <p>Error: <code>Error parsing text SAM file. Not enough fields; File /dev/stdin; Line 105120626...</code></p> <p>Certain SRA-derived or dbGaP datasets can contain duplicate reads.</p> <p>When piping BWA output into <code>AddOrReplaceReadGroups</code>, you may need to remove secondary (<code>0x100</code>) and supplementary (<code>0x800</code>) alignments.</p> <p>This can prevent duplicate-read collisions in downstream Picard/GATK steps.</p> <p>Solution: Uncomment the following line in <code>wes_single.sh</code>:</p> <p><code>| $SAM view -bSh -F 0x900 -</code> - MTOOLBOX Errors</p> </li> </ul> <p>- Failure related to unsupported N_CIGAR:   Add flag <code>--filter_reads_with_N_cigar</code> in Mtoolbox.sh (line ~386).</p> <p>- Samples with coverage below ~10x yield unreliable heteroplasmy fractions (HF). Extremely low coverage (&lt;10x) can render HFs meaningless, despite generally consistent results across widely varying coverage levels.</p> </li> </ul>"},{"location":"usage/usage/#citation","title":"CITATION","text":"<p>To be determined.</p>"},{"location":"usage/usage/#author","title":"AUTHOR","text":"<p>Written by Manuel Rueda (mrueda). GitHub repository: https://github.com/CNAG-Biomedical-Informatics/cbicall.</p>"},{"location":"usage/usage/#copyright-and-license","title":"COPYRIGHT AND LICENSE","text":"<p>Please see the included LICENSE file for distribution and usage terms.</p>"}]}